{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "original_sent = input(\"> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tokens = nltk.word_tokenize(original_sent)\n",
    "original_tokens = [w.lower() for w in original_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'have', 'forgotten', 'that', 'tomato', 'is', 'bad', '.']\n"
     ]
    }
   ],
   "source": [
    "print(original_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronunciation as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# step1_tokens = P.get_similars(\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     original_tokens,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     P.mapping_cmu,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     P.simfunc_lcs(rel_thres=0.8, abs_thres=2)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m step1_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_similars\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping_soundex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimfunc_lcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_thres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabs_thres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(step1_tokens)\n",
      "File \u001b[0;32m~/Desktop/학교 수업/24년 봄/파이썬을 통한 자연언어처리/Project/cs372-ProjectRhymer/pronunciation.py:115\u001b[0m, in \u001b[0;36mget_similars\u001b[0;34m(tokens, mapping_func, similarity_func)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_similars\u001b[39m(tokens: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], mapping_func: MappingFn, similarity_func: SimilarityFn):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mget_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_func\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/학교 수업/24년 봄/파이썬을 통한 자연언어처리/Project/cs372-ProjectRhymer/pronunciation.py:116\u001b[0m, in \u001b[0;36mget_similars.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_similars\u001b[39m(tokens: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], mapping_func: MappingFn, similarity_func: SimilarityFn):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: (x, \u001b[38;5;28mlist\u001b[39m(\u001b[43mget_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_func\u001b[49m\u001b[43m)\u001b[49m)),\n\u001b[1;32m    117\u001b[0m         tokens))\n",
      "File \u001b[0;32m~/Desktop/학교 수업/24년 봄/파이썬을 통한 자연언어처리/Project/cs372-ProjectRhymer/pronunciation.py:109\u001b[0m, in \u001b[0;36mget_similar\u001b[0;34m(word, mapping_func, similarity_func)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m curr \u001b[38;5;129;01min\u001b[39;00m _wordlist:\n\u001b[1;32m    108\u001b[0m     pr \u001b[38;5;241m=\u001b[39m mapping_func(curr)\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpronuns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_func\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    110\u001b[0m         result\u001b[38;5;241m.\u001b[39madd(curr)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/학교 수업/24년 봄/파이썬을 통한 자연언어처리/Project/cs372-ProjectRhymer/pronunciation.py:81\u001b[0m, in \u001b[0;36m_is_similar\u001b[0;34m(As, Bs, similarity_func)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m A \u001b[38;5;129;01min\u001b[39;00m As:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m B \u001b[38;5;129;01min\u001b[39;00m Bs:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msimilarity_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/학교 수업/24년 봄/파이썬을 통한 자연언어처리/Project/cs372-ProjectRhymer/pronunciation.py:75\u001b[0m, in \u001b[0;36msimfunc_lcs.<locals>.<lambda>\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimfunc_lcs\u001b[39m(rel_thres\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, abs_thres\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SimilarityFn:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m A, B: \u001b[43m_check_similarity_lcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_thres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_thres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabs_thres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabs_thres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/학교 수업/24년 봄/파이썬을 통한 자연언어처리/Project/cs372-ProjectRhymer/pronunciation.py:69\u001b[0m, in \u001b[0;36m_check_similarity_lcs\u001b[0;34m(A, B, rel_thres, abs_thres)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_similarity_lcs\u001b[39m(A: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], B: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], rel_thres\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, abs_thres\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 69\u001b[0m     lcs_len \u001b[38;5;241m=\u001b[39m \u001b[43mmisc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lcs_len\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     min_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(A), \u001b[38;5;28mlen\u001b[39m(B))\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (min_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (lcs_len \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_len \u001b[38;5;241m*\u001b[39m rel_thres) \u001b[38;5;129;01mand\u001b[39;00m (lcs_len \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m abs_thres)\n",
      "File \u001b[0;32m~/Desktop/학교 수업/24년 봄/파이썬을 통한 자연언어처리/Project/cs372-ProjectRhymer/misc.py:29\u001b[0m, in \u001b[0;36mget_lcs_len\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m     27\u001b[0m la \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(A)\n\u001b[1;32m     28\u001b[0m lb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(B)\n\u001b[0;32m---> 29\u001b[0m dp \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lb \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(la \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(la):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lb):\n",
      "File \u001b[0;32m~/Desktop/학교 수업/24년 봄/파이썬을 통한 자연언어처리/Project/cs372-ProjectRhymer/misc.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m la \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(A)\n\u001b[1;32m     28\u001b[0m lb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(B)\n\u001b[0;32m---> 29\u001b[0m dp \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lb \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(la \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(la):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lb):\n",
      "File \u001b[0;32m~/Desktop/학교 수업/24년 봄/파이썬을 통한 자연언어처리/Project/cs372-ProjectRhymer/misc.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m la \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(A)\n\u001b[1;32m     28\u001b[0m lb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(B)\n\u001b[0;32m---> 29\u001b[0m dp \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lb \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(la \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(la):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lb):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# step1_tokens = P.get_similars(\n",
    "#     original_tokens,\n",
    "#     P.mapping_cmu,\n",
    "#     P.simfunc_lcs(rel_thres=0.8, abs_thres=2)\n",
    "#     )\n",
    "\n",
    "step1_tokens = P.get_similars(\n",
    "    original_tokens,\n",
    "    P.mapping_soundex,\n",
    "    P.simfunc_lcs(rel_thres=0.8, abs_thres=3)\n",
    "    )\n",
    "\n",
    "print(step1_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: sentence-transformers in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from sentence-transformers) (4.41.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.10)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/opt/homebrew/anaconda3/envs/cs372-ProjectRhymer/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "import semantics_first as S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original word:  forgotten  ,  replaced word:  bad  ,  similar word:  forged\n",
      "original word:  forgotten  ,  replaced word:  tomato  ,  similar word:  fraxinella\n",
      "original word:  forgotten  ,  replaced word:  i  ,  similar word:  foursome\n",
      "original word:  forgotten  ,  replaced word:  tomato  ,  similar word:  fringepod\n",
      "original word:  forgotten  ,  replaced word:  tomato  ,  similar word:  Dracontium\n",
      "original word:  forgotten  ,  replaced word:  tomato  ,  similar word:  breakstone\n",
      "original word:  that  ,  replaced word:  tomato  ,  similar word:  toetoe\n",
      "original word:  that  ,  replaced word:  i  ,  similar word:  theta\n",
      "original word:  that  ,  replaced word:  i  ,  similar word:  teth\n",
      "original word:  tomato  ,  replaced word:  have  ,  similar word:  twinned\n",
      "original word:  bad  ,  replaced word:  i  ,  similar word:  beta\n",
      "original word:  bad  ,  replaced word:  is  ,  similar word:  bodied\n",
      "original word:  bad  ,  replaced word:  tomato  ,  similar word:  beet\n",
      "original word:  bad  ,  replaced word:  have  ,  similar word:  bedded\n",
      "original word:  bad  ,  replaced word:  is  ,  similar word:  body\n",
      "original word:  bad  ,  replaced word:  i  ,  similar word:  beth\n",
      "original word:  bad  ,  replaced word:  have  ,  similar word:  bed\n",
      "original word:  bad  ,  replaced word:  i  ,  similar word:  Beta\n",
      "original word:  bad  ,  replaced word:  i  ,  similar word:  Beth\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# step2_tokens_wordnet = S.recommend_semantics_wordnet(step1_tokens, threshold=0.8)\n",
    "\n",
    "# print(step2_tokens_wordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT top_k : [('i', []), ('have', ['get', 'deliver', 'make']), ('forgotten', ['forget']), ('that', []), ('tomato', []), ('is', ['exist']), ('bad', ['big', 'badly', 'tough', 'risky', 'spoiled']), ('.', [])]\n"
     ]
    }
   ],
   "source": [
    "step2_tokens_BERT_topK = S.recommend_semantics_BERT(original_tokens, top_k=500)\n",
    "print(\"BERT top_k :\", step2_tokens_BERT_topK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT threshold : [('i', ['ace', '1', 'one', 'unity', 'single']), ('have', ['get', 'deliver', 'make', 'own', 'possess', 'let', 'take', 'suffer', 'induce', 'give', 'consume', 'receive', 'cause', 'bear', 'stimulate', 'accept', 'throw', 'sustain', 'experience', 'feature', 'hold', 'birth']), ('forgotten', ['forget', 'leave', 'block', 'bury']), ('that', []), ('tomato', []), ('is', ['exist', 'represent', 'be', 'constitute', 'follow', 'comprise', 'cost', 'equal', 'live']), ('bad', ['big', 'badly', 'tough', 'risky', 'spoiled', 'speculative', 'defective', 'unfit', 'forged', 'sorry']), ('.', [])]\n"
     ]
    }
   ],
   "source": [
    "step2_tokens_BERT_threshold = S.recommend_semantics_BERT(original_tokens, threshold=50)\n",
    "print(\"BERT threshold :\", step2_tokens_BERT_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenceBERT top_k : [('i', ['1']), ('have', ['possess', 'give']), ('forgotten', ['forget']), ('that', []), ('tomato', []), ('is', []), ('bad', ['badly', 'defective', 'sorry', 'tough', 'risky']), ('.', [])]\n"
     ]
    }
   ],
   "source": [
    "step2_tokens_sentenceBERT_topK = S.recommend_semantics_sentenceBERT(original_tokens, top_k=500)\n",
    "print(\"sentenceBERT top_k :\", step2_tokens_sentenceBERT_topK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenceBERT threshold : [('i', ['1', 'one', 'single', 'ace']), ('have', ['possess', 'give', 'take', 'let', 'accept', 'experience', 'hold', 'get', 'own', 'suffer', 'sustain', 'receive', 'deliver', 'feature', 'consume', 'make', 'cause', 'induce', 'stimulate']), ('forgotten', ['forget', 'leave', 'bury']), ('that', []), ('tomato', []), ('is', ['be', 'represent', 'constitute', 'exist', 'follow', 'comprise', 'live', 'equal']), ('bad', ['badly', 'defective', 'sorry', 'tough', 'risky', 'unfit', 'spoiled', 'big', 'speculative']), ('.', [])]\n"
     ]
    }
   ],
   "source": [
    "step2_tokens_sentenceBERT_threshold = S.recommend_semantics_sentenceBERT(original_tokens, threshold=100)\n",
    "print(\"sentenceBERT threshold :\", step2_tokens_sentenceBERT_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Io', 'hevi', 'proconvention', 'Tahiti', 'tanwood', 'ice', 'bait', '.']\n"
     ]
    }
   ],
   "source": [
    "# def pick_one(mapped_tokens):\n",
    "#     return list(map(lambda x: x[1][0], mapped_tokens))\n",
    "\n",
    "# step2_tokens = pick_one(step1_tokens)\n",
    "\n",
    "# print(step2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Io hevi proconvention Tahiti tanwood ice bait .\n"
     ]
    }
   ],
   "source": [
    "# output_sent = ' '.join(step2_tokens)\n",
    "\n",
    "# print(output_sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
